{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b844a-190a-4c53-a899-32933acb05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import math as m\n",
    "\n",
    "# Initialize YOLOv8 pose estimation model\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "# Posture thresholds\n",
    "POSTURE_THRESHOLDS = {\n",
    "    'back_angle': 20,        # Degrees from vertical\n",
    "    'face_distance': 0.15,   # Ratio of image height\n",
    "    'hip_level': 0.1,        # Ratio of image height\n",
    "    'neck_inclination': 40,  # Degrees\n",
    "    'torso_inclination': 10  # Degrees\n",
    "}\n",
    "\n",
    "# Keypoint indices (COCO format)\n",
    "KEYPOINTS = {\n",
    "    'NOSE': 0,\n",
    "    'LEFT_SHOULDER': 5,\n",
    "    'RIGHT_SHOULDER': 6,\n",
    "    'LEFT_HIP': 11,\n",
    "    'RIGHT_HIP': 12\n",
    "}\n",
    "\n",
    "# Visualization settings\n",
    "COLORS = {\n",
    "    'good': (0, 255, 0),\n",
    "    'bad': (0, 0, 255),\n",
    "    'warning': (0, 255, 255),\n",
    "    'metrics': (127, 255, 0)\n",
    "}\n",
    "\n",
    "def calculate_vertical_angle(pt1, pt2):\n",
    "    \"\"\"Calculate angle from vertical (degrees)\"\"\"\n",
    "    dx = pt2[0] - pt1[0]\n",
    "    dy = pt2[1] - pt1[1]\n",
    "    return np.degrees(np.arctan2(abs(dx), abs(dy)))\n",
    "\n",
    "def find_angle(x1, y1, x2, y2, x3, y3):\n",
    "    \"\"\"Calculate angle between three points\"\"\"\n",
    "    angle = m.degrees(m.atan2(y3 - y2, x3 - x2) - m.atan2(y1 - y2, x1 - x2))\n",
    "    return angle + 360 if angle < 0 else angle\n",
    "\n",
    "def posture_analysis(keypoints, frame_height):\n",
    "    \"\"\"Analyze posture for a single person\"\"\"\n",
    "    results = {\n",
    "        'back_angle': 0,\n",
    "        'face_distance': 0,\n",
    "        'hip_level': 0,\n",
    "        'neck_inclination': 0,\n",
    "        'torso_inclination': 0,\n",
    "        'messages': []\n",
    "    }\n",
    "\n",
    "    # Get required keypoints\n",
    "    kpt = KEYPOINTS\n",
    "    ls = keypoints[kpt['LEFT_SHOULDER']]\n",
    "    rs = keypoints[kpt['RIGHT_SHOULDER']]\n",
    "    lh = keypoints[kpt['LEFT_HIP']]\n",
    "    rh = keypoints[kpt['RIGHT_HIP']]\n",
    "    nose = keypoints[kpt['NOSE']]\n",
    "\n",
    "    # Calculate midpoints\n",
    "    shoulder_mid = ((ls[0] + rs[0])/2, (ls[1] + rs[1])/2)\n",
    "    hip_mid = ((lh[0] + rh[0])/2, (lh[1] + rh[1])/2)\n",
    "\n",
    "    # Back angle (shoulders to hips)\n",
    "    results['back_angle'] = calculate_vertical_angle(shoulder_mid, hip_mid)\n",
    "    if results['back_angle'] > POSTURE_THRESHOLDS['back_angle']:\n",
    "        results['messages'].append(\"Straighten your back\")\n",
    "\n",
    "    # Face distance from shoulders\n",
    "    results['face_distance'] = abs(nose[1] - shoulder_mid[1]) / frame_height\n",
    "    if results['face_distance'] > POSTURE_THRESHOLDS['face_distance']:\n",
    "        results['messages'].append(\"Align head with shoulders\")\n",
    "\n",
    "    # Hip level alignment\n",
    "    results['hip_level'] = abs(lh[1] - rh[1]) / frame_height\n",
    "    if results['hip_level'] > POSTURE_THRESHOLDS['hip_level']:\n",
    "        results['messages'].append(\"Balance hip position\")\n",
    "\n",
    "    # Neck inclination (nose-shoulder-horizontal)\n",
    "    results['neck_inclination'] = find_angle(\n",
    "        nose[0], nose[1], \n",
    "        shoulder_mid[0], shoulder_mid[1],\n",
    "        shoulder_mid[0], shoulder_mid[1] - 100\n",
    "    )\n",
    "    if results['neck_inclination'] > POSTURE_THRESHOLDS['neck_inclination']:\n",
    "        results['messages'].append(\"Keep head straight\")\n",
    "\n",
    "    # Torso inclination (shoulder-hip-horizontal)\n",
    "    results['torso_inclination'] = find_angle(\n",
    "        shoulder_mid[0], shoulder_mid[1],\n",
    "        hip_mid[0], hip_mid[1],\n",
    "        hip_mid[0], hip_mid[1] - 100\n",
    "    )\n",
    "    if results['torso_inclination'] > POSTURE_THRESHOLDS['torso_inclination']:\n",
    "        results['messages'].append(\"Keep torso upright\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "person_data = {}\n",
    "last_update = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    current_time = time.time()\n",
    "    results = model(frame, verbose=False)[0]\n",
    "    keypoints = results.keypoints.xy.cpu().numpy()\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Process all detected people\n",
    "    for i, person_kpts in enumerate(keypoints):\n",
    "        if i not in person_data:\n",
    "            person_data[i] = {'duration': 0, 'last_seen': current_time}\n",
    "\n",
    "        # Update posture duration\n",
    "        time_diff = current_time - person_data[i]['last_seen']\n",
    "        analysis = posture_analysis(person_kpts, h)\n",
    "        \n",
    "        if len(analysis['messages']) > 0:\n",
    "            person_data[i]['duration'] += time_diff\n",
    "        else:\n",
    "            person_data[i]['duration'] = max(0, person_data[i]['duration'] - time_diff)\n",
    "        \n",
    "        person_data[i]['last_seen'] = current_time\n",
    "\n",
    "        # Visualization\n",
    "        y_offset = 30 + (i * 200)\n",
    "        color = COLORS['bad'] if len(analysis['messages']) > 0 else COLORS['good']\n",
    "        \n",
    "        # Draw skeleton\n",
    "        for kpt in person_kpts:\n",
    "            x, y = int(kpt[0]), int(kpt[1])\n",
    "            cv2.circle(frame, (x, y), 5, color, -1)\n",
    "\n",
    "        # Display metrics\n",
    "        cv2.putText(frame, f\"Person {i+1}\", (10, y_offset), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        cv2.putText(frame, \n",
    "                    f\"Back: {analysis['back_angle']:.1f}° | Neck: {analysis['neck_inclination']:.1f}°\", \n",
    "                    (10, y_offset+30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLORS['metrics'], 1)\n",
    "        cv2.putText(frame, \n",
    "                    f\"Hip Level: {analysis['hip_level']*100:.1f}% | Duration: {person_data[i]['duration']:.1f}s\", \n",
    "                    (10, y_offset+60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLORS['metrics'], 1)\n",
    "\n",
    "        # Display warnings\n",
    "        for j, msg in enumerate(analysis['messages']):\n",
    "            cv2.putText(frame, msg, (w-300, 30 + (j*30)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, COLORS['warning'], 1)\n",
    "\n",
    "    # Cleanup old person data\n",
    "    for pid in list(person_data.keys()):\n",
    "        if current_time - person_data[pid]['last_seen'] > 2:\n",
    "            del person_data[pid]\n",
    "\n",
    "    cv2.imshow('Posture Monitoring', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f9d08-0003-48ec-b33c-53f2f4192e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
